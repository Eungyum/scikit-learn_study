{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMD9b/bGDIc+xxrHH03GmKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eungyum/scikit-learn_study/blob/main/4_4_%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사이킷런 preprocessing\n",
        "\n",
        "\n",
        "\n",
        "*   StandardScaler : 평균을 0, 분산을 1로 스케일링\n",
        "*   MinMaxScaler : 0에서 1사이로 스케일링\n",
        "*   MaxAbsScaler : -1에서 1사이로 스케일링\n",
        "*   RobustScaler : 이상치의 영향을 최소화하는 스케일링\n",
        "*   QuantileTransformer\n",
        "*   Normalizer : 샘플별 정규화\n",
        "\n"
      ],
      "metadata": {
        "id": "qQwvO1hZVQEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 스탠다드"
      ],
      "metadata": {
        "id": "1fKv2HGhWPMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = np.array([[0, 1], [2, 3], [4, 5]])\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "id": "F5F8nyWlWNra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Min-Max"
      ],
      "metadata": {
        "id": "s5xeCuN_Wd-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = np.array([[0, 1], [2, 3], [4, 5]])\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "id": "VlfL44opWUiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MaxAbs"
      ],
      "metadata": {
        "id": "kondofT4Wjxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "import numpy as np\n",
        "\n",
        "# 무작위로 데이터 생성 (5개의 특성과 10개의 샘플)\n",
        "data = np.array([\n",
        "    [1.0, 2.0, 3.0, 4.0, 5.0],\n",
        "    [2.0, 3.0, 4.0, 5.0, 6.0],\n",
        "    [3.0, 4.0, 5.0, 6.0, 7.0],\n",
        "    [4.0, 5.0, 6.0, 7.0, 8.0],\n",
        "    [5.0, 6.0, 7.0, 8.0, 9.0],\n",
        "    [6.0, 7.0, 8.0, 9.0, 10.0],\n",
        "    [7.0, 8.0, 9.0, 10.0, 11.0],\n",
        "    [8.0, 9.0, 10.0, 11.0, 12.0],\n",
        "    [9.0, 10.0, 11.0, 12.0, 13.0],\n",
        "    [10.0, 11.0, 12.0, 13.0, 14.0]\n",
        "])\n",
        "\n",
        "# MaxAbsScaler 객체 생성\n",
        "scaler = MaxAbsScaler()\n",
        "\n",
        "# 스케일링 파라미터 학습 및 변환\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# 스케일링 결과 출력\n",
        "print(\"원본 데이터:\\n\", data)\n",
        "print(\"스케일링된 데이터:\\n\", scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjGWHJAEWhdt",
        "outputId": "44b86bed-7f80-4df9-c0e0-77900bdf656a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 데이터:\n",
            " [[ 1.  2.  3.  4.  5.]\n",
            " [ 2.  3.  4.  5.  6.]\n",
            " [ 3.  4.  5.  6.  7.]\n",
            " [ 4.  5.  6.  7.  8.]\n",
            " [ 5.  6.  7.  8.  9.]\n",
            " [ 6.  7.  8.  9. 10.]\n",
            " [ 7.  8.  9. 10. 11.]\n",
            " [ 8.  9. 10. 11. 12.]\n",
            " [ 9. 10. 11. 12. 13.]\n",
            " [10. 11. 12. 13. 14.]]\n",
            "스케일링된 데이터:\n",
            " [[0.1        0.18181818 0.25       0.30769231 0.35714286]\n",
            " [0.2        0.27272727 0.33333333 0.38461538 0.42857143]\n",
            " [0.3        0.36363636 0.41666667 0.46153846 0.5       ]\n",
            " [0.4        0.45454545 0.5        0.53846154 0.57142857]\n",
            " [0.5        0.54545455 0.58333333 0.61538462 0.64285714]\n",
            " [0.6        0.63636364 0.66666667 0.69230769 0.71428571]\n",
            " [0.7        0.72727273 0.75       0.76923077 0.78571429]\n",
            " [0.8        0.81818182 0.83333333 0.84615385 0.85714286]\n",
            " [0.9        0.90909091 0.91666667 0.92307692 0.92857143]\n",
            " [1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RobustScaler\n",
        "- x^ = (x-q2(x))/(q3(x)-q1(x))"
      ],
      "metadata": {
        "id": "KFEVWD4_XOo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "data = np.array([[0, 1], [2, 3], [4, 5]])\n",
        "scaler = RobustScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h9Ci8PVW4WT",
        "outputId": "d001e84d-f613-4047-ee7e-fa0ddd178b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1. -1.]\n",
            " [ 0.  0.]\n",
            " [ 1.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QuantileTransformer"
      ],
      "metadata": {
        "id": "tOERuy7GXffD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "data = np.array([[0, 1], [2, 3], [4, 5]])\n",
        "scaler = QuantileTransformer()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3cEuoETXVbS",
        "outputId": "a9284079-38fc-4103-98de-8a00223df682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (3). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 샘플별 정규화\n",
        "- Normalizer : 샘플의 유클리디안 거리가 1이 되도록 정규화\n",
        "- 각 샘플에 대해 독립적으로 수행\n",
        "- 텍스트 데이터나 클러스터링같은 분야에서 유용하게 사용"
      ],
      "metadata": {
        "id": "43blNc0vXkxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "import pandas as pd\n",
        "\n",
        "# 샘플 데이터셋 생성\n",
        "data = {\n",
        "    'feature1': [1, 20, 300],\n",
        "    'feature2': [2, 30, 400],\n",
        "    'feature3': [3, 40, 500]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Normalizer 인스턴스 생성\n",
        "normalizer = Normalizer(norm='l2')  # 기본 노름은 'l2'\n",
        "\n",
        "# 데이터 정규화\n",
        "normalized_data = normalizer.transform(df)\n",
        "\n",
        "# 정규화된 데이터를 DataFrame으로 변환 및 출력\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
        "print(normalized_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXRb7s-TXiqb",
        "outputId": "b7c6358f-6c6f-4129-c635-994c3c56b4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   feature1  feature2  feature3\n",
            "0  0.267261  0.534522  0.801784\n",
            "1  0.371391  0.557086  0.742781\n",
            "2  0.424264  0.565685  0.707107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but Normalizer was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}